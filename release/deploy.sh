#!/bin/bash

# Script to deploy Cas Contact client to prod.
#
# The canonical place for our releases are the Docker Images in Docker Hub.
# They are generated by CircleCI in an untainted way.
#
# The client gets released by deploying static files on OVH storage.
#
# Environment variables required:
# - None for now.
#
# AWS CLI must be installed, and configured for a user with the cas-contact-deploy policy:
# https://console.aws.amazon.com/iam/home?region=us-east-1#/policies/arn:aws:iam::951168128976:policy/cas-contact-deploy$serviceLevelSummary
# That policy must be kept in sync with the actual actions used in this file.
#
# Optional:
# - CIRCLE_STAGE: if "deploy", the script will know it's run as part of Circle CI deployment.
# - DRY_RUN: do not actually deploy.
#
# Usage:
# release/deploy.sh $CIRCLE_TAG

set -e
readonly DIRNAME=$(dirname "$0")

if [ -n "$DRY_RUN" ]; then
  echo 'DRY RUN: will not actually modify anything.'
fi

readonly TAG="$1"
if [ -z "$TAG" ]; then
  echo 'No tag provided.'
  exit 1
fi

if [ -z "$(git tag -l "$TAG")" ]; then
  echo "The tag $TAG does not exist locally."
  exit 2
fi

if ! command -v aws >/dev/null 2>&1; then
  echo 'Install and configure the aws CLI that is necessary for deployment.'
  echo "* Ask your favorite admin for the access to the AWS project if you do not have it yet"
  echo "* Make sure you have the action rights to the cas-contact-deploy policy (or equivalent)"
  echo "* Log into your AWS console and go to IAM (https://console.aws.amazon.com/iam/home)"
  echo "* Create a new 'Access key ID' and the corresponding 'Secret' if you do not already have one"
  echo "* Run 'aws configure' and add your credentials (make sure to set the region to 'eu-west-3')"
  exit 3
fi

readonly DOCKER_TAG="tag-$TAG"
readonly DOCKER_REPO="bayesimpact/cas-contact"
readonly DOCKER_IMAGE="$DOCKER_REPO:$DOCKER_TAG"
# Our s3 bucket, see
# https://s3.console.aws.amazon.com/s3/buckets/cas-contact-client/?region=eu-west-3&tab=overview
readonly S3_BUCKET=cas-contact-client

function docker_tag_exists {
  local image=$1
  local tag=$2
  curl --silent -f -lSL "https://index.docker.io/v1/repositories/$image/tags/$tag" > /dev/null
}

echo 'Checking that the Docker images exists…'
if (! docker_tag_exists $DOCKER_REPO $DOCKER_TAG); then
  echo "The tag $DOCKER_TAG is not present in Docker Registry."
  exit 10
fi

# To get the files, this script downloads the Docker Images from Docker
# Registry, then extract the html folder from the Docker Image (note that to do
# that we need to create a temporary container using that image). The html
# folder is extracted as a TAR archive that we unpack in a local dir.
#
# Once we have the file we can upload them to S3.

echo 'Downloading the client Docker Image…'
docker pull $DOCKER_IMAGE

echo 'Extracting the archive from the Docker Image…'
readonly TMP_TAR_FILE="$(mktemp).tar"
readonly TMP_DOCKER_CONTAINER=$(docker create $DOCKER_IMAGE)
docker cp $TMP_DOCKER_CONTAINER:/usr/share/app/html - > $TMP_TAR_FILE
docker rm $TMP_DOCKER_CONTAINER

echo 'Extracting files from the archive…'
readonly TMP_DIR=$(mktemp -d)
tar -xf $TMP_TAR_FILE -C $TMP_DIR --strip-components 1
rm -r $TMP_TAR_FILE

echo 'Uploading files to the S3 bucket…'
pushd $TMP_DIR
if [ -z "$DRY_RUN" ]; then
  aws s3 cp "$(pwd)" "s3://$S3_BUCKET/" --recursive
fi
popd

rm -r $TMP_DIR

# TODO(pascal): Update the GitHub release, change the prod branch, warn slack.
